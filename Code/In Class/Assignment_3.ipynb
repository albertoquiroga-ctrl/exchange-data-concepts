{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "id":  "a170c570",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# ECON7880 â€” Assignment 3 (Template)\n",
                                     "\n",
                                     "**Notes**  \n",
                                     "- **Note 1:** for answers with Python, display both codes and results clearly.  \n",
                                     "- **Note 2:** for answers with manual calculation, please display all calculation steps clearly.\n",
                                     "\n",
                                     "This notebook mirrors the structure and style you used for Assignment 2: a brief environment setup followed by one section per question, each with Markdown of the question text and ready-to-run code stubs."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "51e4802a",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 0) Environment Setup"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "2c671971",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# Core libraries\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "\n",
                                     "# Viz\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "\n",
                                     "# ML utilities (you can import more as needed)\n",
                                     "from sklearn.neighbors import KNeighborsClassifier\n",
                                     "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc\n",
                                     "\n",
                                     "# Plot settings\n",
                                     "plt.rcParams[\u0027figure.figsize\u0027] = (7.5, 5.0)\n",
                                     "plt.rcParams[\u0027axes.grid\u0027] = True\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "a156722b",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 1) Question 1. [30 points @ 6 points each]\n",
                                     "\n",
                                     "A firm collected 5 training instances with 2 features $X_1$ and $X_2$, and their **Type** values:\n",
                                     "\n",
                                     "| Instance | $X_1$ | $X_2$ | Type |\n",
                                     "|:--:|:--:|:--:|:--:|\n",
                                     "| 0 | 13.4 | 11.2 | 1 |\n",
                                     "| 1 | 7.9  | 2.1  | 0 |\n",
                                     "| 2 | 7.1  | 8.9  | 1 |\n",
                                     "| 3 | 7.3  | 6.9  | 0 |\n",
                                     "| 4 | 10.7 | 8.9  | 1 |\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "5c95d35f",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(a)** Use Python to plot the 5 instances with $X_1$ on the x-axis and $X_2$ on the y-axis. Visualize instances with different color according to their **Type** values.\n",
                                     "\n",
                                     "With a new instance with $(X_1, X_2) = (6.5, 2.1)$, complete the following tasks with either Python or manual calculation. **Round results to 4 decimal places if you use manual calculation. No need to round if you work with Python.**\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "4dfa7755",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q1 (a) Plot points by Type ---\n",
                                     "import pandas as pd\n",
                                     "import matplotlib.pyplot as plt\n",
                                     "\n",
                                     "train = pd.DataFrame({\n",
                                     "    \"Instance\": [0, 1, 2, 3, 4],\n",
                                     "    \"X1\": [13.4, 7.9, 7.1, 7.3, 10.7],\n",
                                     "    \"X2\": [11.2, 2.1, 8.9, 6.9, 8.9],\n",
                                     "    \"Type\": [1, 0, 1, 0, 1]\n",
                                     "})\n",
                                     "new_pt = pd.Series({\"X1\": 6.5, \"X2\": 2.1})\n",
                                     "\n",
                                     "# Scatter plot\n",
                                     "fig, ax = plt.subplots()\n",
                                     "for t, df_g in train.groupby(\"Type\"):\n",
                                     "    ax.scatter(df_g[\"X1\"], df_g[\"X2\"], label=f\"Type={t}\", s=70)\n",
                                     "ax.scatter(new_pt[\"X1\"], new_pt[\"X2\"], marker=\"*\", s=200, label=\"New point\")\n",
                                     "ax.set_xlabel(\"X1\")\n",
                                     "ax.set_ylabel(\"X2\")\n",
                                     "ax.legend()\n",
                                     "plt.show()\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "1247479c",
                      "source":  [
                                     "**Answer (a):** The matplotlib scatter plot shows Type=1 and Type=0 points in different colors with the new case at $(6.5, 2.1)$ highlighted by a star. Visually it sits next to the lower-left Type 0 cluster near $(7, 2)$, foreshadowing the distance calculations below."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "30e287d4",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(b)** Calculate the **Euclidean Distance** between the new instance and each training instance using both $X_1$ and $X_2$.\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "ae65f79e",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q1 (b) Euclidean distance to new_pt ---\n",
                                     "import numpy as np\n",
                                     "\n",
                                     "def euclidean(u, v):\n",
                                     "    u = np.asarray(u); v = np.asarray(v)\n",
                                     "    return float(np.linalg.norm(u - v))\n",
                                     "\n",
                                     "new_xy = np.array([new_pt[\"X1\"], new_pt[\"X2\"]])\n",
                                     "train[\"euclid_dist\"] = train[[\"X1\",\"X2\"]].apply(lambda r: euclidean(r.values, new_xy), axis=1)\n",
                                     "train[[\"Instance\",\"X1\",\"X2\",\"Type\",\"euclid_dist\"]]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "1ff0d897",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(c)** Calculate the **Cosine Distance** between the new instance and each training instance using both $X_1$ and $X_2$.\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "8405e282",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q1 (c) Cosine distance to new_pt ---\n",
                                     "def cosine_distance(u, v):\n",
                                     "    u = np.asarray(u); v = np.asarray(v)\n",
                                     "    num = np.dot(u, v)\n",
                                     "    den = np.linalg.norm(u) * np.linalg.norm(v)\n",
                                     "    cos_sim = num / den\n",
                                     "    return float(1 - cos_sim)\n",
                                     "\n",
                                     "train[\"cosine_dist\"] = train[[\"X1\",\"X2\"]].apply(lambda r: cosine_distance(r.values, new_xy), axis=1)\n",
                                     "train[[\"Instance\",\"X1\",\"X2\",\"Type\",\"euclid_dist\",\"cosine_dist\"]].sort_values(\"Instance\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "8d692118",
                      "source":  [
                                     "**Answers (b)–(c):** Distances from the new case to each training instance using both metrics.",
                                     "",
                                     "| Instance | X1 | X2 | Type | Euclidean Distance | Cosine Distance |",
                                     "|---:|---:|---:|:--:|---:|---:|",
                                     "| 0 | 13.4 | 11.2 | 1 | 11.4202 | 0.0727 |",
                                     "| 1 | 7.9 | 2.1 | 0 | 1.4000 | 0.0014 |",
                                     "| 2 | 7.1 | 8.9 | 1 | 6.8264 | 0.1663 |",
                                     "| 3 | 7.3 | 6.9 | 0 | 4.8662 | 0.0973 |",
                                     "| 4 | 10.7 | 8.9 | 1 | 7.9925 | 0.0718 |",
                                     "",
                                     "The Euclidean distances define the neighbor order for parts (d)–(e); cosine distance is used for the majority-vote classifier in (d)."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "be2a76c0",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(d)** What is the predicted **Type** value for the new instance using **3-NN and majority vote (based on Cosine Distance)**? What is the estimated class probability?\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "4a4a4eb1",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q1 (d) 3-NN majority vote using COSINE distance ---\n",
                                     "k = 3\n",
                                     "nbrs_cos = train.sort_values(\"cosine_dist\").head(k)\n",
                                     "pred_type_majority = int((nbrs_cos[\"Type\"].sum() \u003e= (k/2)))  # tie -\u003e 1\n",
                                     "prob_majority = nbrs_cos[\"Type\"].mean()\n",
                                     "\n",
                                     "print(f\"Predicted Type (3-NN majority on cosine): {pred_type_majority}\")\n",
                                     "print(f\"Estimated class probability: {prob_majority:.4f}\")\n",
                                     "nbrs_cos[[\"Instance\",\"Type\",\"cosine_dist\"]]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (d):** The three cosine-distance neighbors are instances 1, 4, and 0; two of them have Type=1, so 3-NN majority predicts `Type = 1` with an estimated class probability of 0.6667.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "388a4715",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(e)** Whatâ€™s the predicted **Type** value for the new instance using **3-NN and weighted voting (based on Euclidean Distance)**? What is the estimated class probability?\n",
                                     "\n",
                                     "Please report the results in one or two tables. For example, answers for Q1(b)-(c) can be organized as below:\n",
                                     "\n",
                                     "| Instance | X1 | X2 | Type | (b) Euclidean Distance | (c) Cosine Distance |\n",
                                     "|---:|---:|---:|---:|---:|---:|\n",
                                     "| 0 | 13.4 | 11.2 | 1 |   |   |\n",
                                     "| 1 | 7.9  | 2.1  | 0 |   |   |\n",
                                     "| 2 | 7.1  | 8.9  | 1 |   |   |\n",
                                     "| 3 | 7.3  | 6.9  | 0 |   |   |\n",
                                     "| 4 | 10.7 | 8.9  | 1 |   |   |"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "21cffeaf",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q1 (e) 3-NN weighted vote using EUCLIDEAN distance ---\n",
                                     "# Weights = 1 / distance (guarding against zero distance)\n",
                                     "eps = 1e-9\n",
                                     "nbrs_euc = train.sort_values(\"euclid_dist\").head(3).copy()\n",
                                     "nbrs_euc[\"w\"] = 1.0 / (nbrs_euc[\"euclid_dist\"] + eps)\n",
                                     "weighted_sum = (nbrs_euc[\"w\"] * nbrs_euc[\"Type\"]).sum()\n",
                                     "total_w = nbrs_euc[\"w\"].sum()\n",
                                     "prob_weighted = float(weighted_sum / total_w)\n",
                                     "pred_type_weighted = int(prob_weighted \u003e= 0.5)\n",
                                     "\n",
                                     "print(f\"Predicted Type (3-NN weighted on euclidean): {pred_type_weighted}\")\n",
                                     "print(f\"Estimated class probability: {prob_weighted:.4f}\")\n",
                                     "nbrs_euc[[\"Instance\",\"Type\",\"euclid_dist\",\"w\"]]\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (e):** Inverse-distance weights heavily favor instance 1 (Type=0), so the weighted 3-NN vote predicts `Type = 0` with an estimated probability of 0.1374 for Type=1.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "071326ed",
                      "source":  [
                                     "**Details for (e):** 3-NN uses the three smallest Euclidean distances (flagged \"Yes\") and inverse-distance weights $w_i = 1/d_i$.",
                                     "",
                                     "| Instance | Type | Euclidean Distance | Weight $1/d_i$ | Used in 3-NN? |",
                                     "|---:|:--:|---:|---:|:---:|",
                                     "| 0 | 1 | 11.4202 | 0.0876 | No |",
                                     "| 1 | 0 | 1.4000 | 0.7143 | Yes |",
                                     "| 2 | 1 | 6.8264 | 0.1465 | Yes |",
                                     "| 3 | 0 | 4.8662 | 0.2055 | Yes |",
                                     "| 4 | 1 | 7.9925 | 0.1251 | No |",
                                     "",
                                     "Using only the three nearest neighbors (as required by 3-NN) gives $P(Type=1) = 0.1374$ and predicts Type 0 because the two closest points are both Type 0."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "70ff026f",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 2) Question 2. [30 points]\n",
                                     "\n",
                                     "A firm collected 6 instances with 2 features $X_1$ and $X_2$:\n",
                                     "\n",
                                     "| Instance | $X_1$ | $X_2$ |\n",
                                     "|:--:|:--:|:--:|\n",
                                     "| 0 | 1 | 4 |\n",
                                     "| 1 | 1 | 3 |\n",
                                     "| 2 | 0 | 5 |\n",
                                     "| 3 | 5 | 2 |\n",
                                     "| 4 | 6 | 3 |\n",
                                     "| 5 | 4 | 0 |\n",
                                     "\n",
                                     "With instance **0** and **3** selected as initial centroids, weâ€™d like to simulate the **$k$-means** algorithm to separate all instances into two clusters ($k=2$). Complete the following with Python or manual calculation. **Round results to 4 decimal places if manual calculation; no need to round if using Python.**\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "c0b5dbbc",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(a)** Compute Euclidean distance from each instance to the initial centroids.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "96a581b3",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q2 setup \u0026 (a) Distances to initial centroids ---\n",
                                     "points = np.array([\n",
                                     "    [1, 4],\n",
                                     "    [1, 3],\n",
                                     "    [0, 5],\n",
                                     "    [5, 2],\n",
                                     "    [6, 3],\n",
                                     "    [4, 0],\n",
                                     "], dtype=float)\n",
                                     "\n",
                                     "idx0, idx3 = 0, 3\n",
                                     "centroids = np.vstack([points[idx0], points[idx3]])  # initial centroids (instances 0 and 3)\n",
                                     "\n",
                                     "def pairwise_euclid(a, b):\n",
                                     "    # a: (n, d), b: (m, d) -\u003e (n, m)\n",
                                     "    return np.linalg.norm(a[:, None, :] - b[None, :, :], axis=2)\n",
                                     "\n",
                                     "dists = pairwise_euclid(points, centroids)\n",
                                     "df2 = pd.DataFrame(points, columns=[\"X1\", \"X2\"])\n",
                                     "df2.insert(0, \"Instance\", range(len(df2)))\n",
                                     "df2[\"dist_c0\"] = dists[:, 0]\n",
                                     "df2[\"dist_c1\"] = dists[:, 1]\n",
                                     "df2\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "278965b9",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(b)** Assign instances to the two clusters by finding their closest centroids.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "c9ce9f76",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q2 (b) Cluster assignments via nearest centroid ---\n",
                                     "assign = dists.argmin(axis=1)\n",
                                     "df2[\"cluster\"] = assign\n",
                                     "df2\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "50d8083a",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(c)** Compute the clustering quality with $\\text{SSE} = \\sum_{i=1}^k \\sum_{p \\in C_i} d(p, m_i)^2$.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "74088f5a",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q2 (c) SSE for current clustering ---\n",
                                     "sse = float(np.sum((dists[np.arange(len(points)), assign]) ** 2))\n",
                                     "print(f\"SSE (iteration 1): {sse:.4f}\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "8416a2af",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(d)** Compute the **mean feature values** for instances in the two clusters respectively, in the format of $(X_1, X_2)$.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "649ab842",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q2 (d) Updated centroids from cluster means ---\n",
                                     "means = np.vstack([\n",
                                     "    points[assign == 0].mean(axis=0),\n",
                                     "    points[assign == 1].mean(axis=0),\n",
                                     "])\n",
                                     "print(\"Updated centroids (iteration 1 means):\", means)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "c87b110a",
                      "source":  [
                                     "**Answers (a)–(d):** Distances to the initial centroids (instances 0 and 3) together with the resulting cluster labels.",
                                     "",
                                     "| Instance | X1 | X2 | Dist to Inst 0 | Dist to Inst 3 | Cluster (iter 1) |",
                                     "|---:|---:|---:|---:|---:|:--:|",
                                     "| 0 | 1 | 4 | 0.0000 | 4.4721 | 0 |",
                                     "| 1 | 1 | 3 | 1.0000 | 4.1231 | 0 |",
                                     "| 2 | 0 | 5 | 1.4142 | 5.8310 | 0 |",
                                     "| 3 | 5 | 2 | 4.4721 | 0.0000 | 1 |",
                                     "| 4 | 6 | 3 | 5.0990 | 1.4142 | 1 |",
                                     "| 5 | 4 | 0 | 5.0000 | 2.2361 | 1 |",
                                     "",
                                     "SSE (iteration 1) = 10.0000. Cluster means for part (d): $C_0 = (0.667, 4.000)$ and $C_1 = (5.000, 1.667)$."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "e7699812",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(e)** **Update** the cluster centroids with the means from (d), then repeat steps (a)â€“(d) once. Will the clustering result (i.e., cluster labels) change? Any improvement in terms of **SSE**?\n",
                                     "\n",
                                     "**Suggested table for (a)â€“(d):**\n",
                                     "\n",
                                     "| Instance | X1 | X2 | (a) Dist to **Inst 0** | (a) Dist to **Inst 3** | (b) Cluster Label | (d) Updated Centroid |\n",
                                     "|---:|---:|---:|---:|---:|:--:|:--:|\n",
                                     "| 0 |   |   |   |   |   |   |\n",
                                     "| â€¦ |   |   |   |   |   |   |\n",
                                     "| 5 |   |   |   |   |   |   |\n",
                                     "\n",
                                     "**(c) SSE:** ____"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "e4e8b95d",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q2 (e) Repeat after updating centroids ---\n",
                                     "centroids2 = means.copy()\n",
                                     "d2 = pairwise_euclid(points, centroids2)\n",
                                     "assign2 = d2.argmin(axis=1)\n",
                                     "sse2 = float(np.sum((d2[np.arange(len(points)), assign2]) ** 2))\n",
                                     "\n",
                                     "df2_iter2 = pd.DataFrame(points, columns=[\"X1\", \"X2\"])\n",
                                     "df2_iter2.insert(0, \"Instance\", range(len(df2_iter2)))\n",
                                     "df2_iter2[\"dist_c0\"] = d2[:, 0]\n",
                                     "df2_iter2[\"dist_c1\"] = d2[:, 1]\n",
                                     "df2_iter2[\"cluster\"] = assign2\n",
                                     "\n",
                                     "display(df2_iter2)\n",
                                     "print(f\"SSE (iteration 2): {sse2:.4f}\")\n",
                                     "print(\"Centroids (iteration 2):\", centroids2)\n",
                                     "print(\"Did labels change?\", not np.array_equal(assign, assign2))\n",
                                     "print(f\"SSE improvement: {sse - sse2:.4f}\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (e):** After updating the centroids to (0.667, 4.000) and (5.000, 1.667), every instance keeps the same label `[0,0,0,1,1,1]`, but SSE drops from 10.0000 to 9.3333 (an improvement of 0.6667).\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "7569d842",
                      "source":  [
                                     "**Iteration 2 check for part (e):** Distances to the updated centroids and confirmation that labels are unchanged.",
                                     "",
                                     "| Instance | Dist to $C_0=(0.667, 4.000)$ | Dist to $C_1=(5.000, 1.667)$ | Cluster (iter 2) |",
                                     "|---:|---:|---:|:--:|",
                                     "| 0 | 0.3333 | 4.6308 | 0 |",
                                     "| 1 | 1.0541 | 4.2164 | 0 |",
                                     "| 2 | 1.2019 | 6.0093 | 0 |",
                                     "| 3 | 4.7726 | 0.3333 | 1 |",
                                     "| 4 | 5.4263 | 1.6667 | 1 |",
                                     "| 5 | 5.2068 | 1.9437 | 1 |",
                                     "",
                                     "SSE (iteration 2) = 9.3333, so the procedure improves the objective by 0.6667 while keeping the same labels."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "a42a71cc",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 3) Question 3. [24 points]\n",
                                     "\n",
                                     "A bank trained a classification model to predict the likelihood of default for each customer. There are **1000 customers** in the database: the â€œNo Defaultâ€ cases take up **80%** of the data while the â€œDefaultâ€ cases take up **20%**. Applying this classifier on this dataset yields the following confusion matrix:\n",
                                     "\n",
                                     "**Confusion matrix**\n",
                                     "\n",
                                     "|              | Predicted: Default | Predicted: No Default |\n",
                                     "|:-------------|-------------------:|----------------------:|\n",
                                     "| **Actual: Default**    | 150 | 50  |\n",
                                     "| **Actual: No Default** | 100 | 700 |\n",
                                     "\n",
                                     "As the average lending amount is **$100** and interest rate is **15%**, the **cost-benefit matrix** (negative numbers mean cost) is:\n",
                                     "\n",
                                     "|              | Predicted: Default | Predicted: No Default |\n",
                                     "|:-------------|-------------------:|----------------------:|\n",
                                     "| **Actual: Default**    | $0  | $100 |\n",
                                     "| **Actual: No Default** | $0  | $15  |\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "4ff6f180",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(a)** Which group (â€œDefaultâ€ or â€œNo Defaultâ€) will you consider as the positive class?  \n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (a):** Treat `Default` as the positive class because the firm\u0027s goal is to catch defaults; all recall/precision metrics therefore refer to the default customers.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "d6646647",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(b)** **[8 points @ 2 points each]** Calculate the following scores for this model: (i) **Accuracy**; (ii) **True positive rate (Sensitivity/Recall)**; (iii) **True negative rate (Specificity)**; (iv) **Precision (for the positive class only)**.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "8fba3103",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q3 setup \u0026 (b) Classification metrics ---\n",
                                     "cm = np.array([[150, 50],\n",
                                     "               [100, 700]])\n",
                                     "TP, FN = cm[0, 0], cm[0, 1]\n",
                                     "FP, TN = cm[1, 0], cm[1, 1]\n",
                                     "\n",
                                     "N = cm.sum()\n",
                                     "pos = cm[0].sum()\n",
                                     "neg = cm[1].sum()\n",
                                     "\n",
                                     "accuracy = (TP + TN) / N\n",
                                     "tpr = TP / pos\n",
                                     "tnr = TN / neg\n",
                                     "precision = TP / (TP + FP)\n",
                                     "\n",
                                     "print(f\"Accuracy:  {accuracy:.4f}\")\n",
                                     "print(f\"TPR:       {tpr:.4f}\")\n",
                                     "print(f\"TNR:       {tnr:.4f}\")\n",
                                     "print(f\"Precision: {precision:.4f}\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (b):** Accuracy = 0.8500, TPR = 0.7500, TNR = 0.8750, Precision (Default) = 0.6000.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "4d88a950",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(c)** Calculate the **expected value (per person)** for this model.  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "14b96244",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q3 (c) Expected value per person ---\n",
                                     "benefit = np.array([[0, -100],\n",
                                     "                    [0,   15]], dtype=float)\n",
                                     "ev_total = float((cm * benefit).sum())\n",
                                     "ev_per_person = ev_total / N\n",
                                     "print(f\"Expected value per person (this model): ${ev_per_person:.4f}\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (c):** Using the cost-benefit matrix (default + approved loan costs $100, hence -$100), the model yields $5,500 total benefit, i.e., **$5.50 per customer**.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "37f59c59",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(d)** Assume we aim to target the same proportion of customers as in the first table, with only **positive predictions** targeted. **Write down the confusion matrix for a random classifier.**  \n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "2abbb722",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q3 (d) Random classifier confusion matrix ---\n",
                                     "pred_pos_rate = (TP + FP) / N\n",
                                     "rand_tp = round(pos * pred_pos_rate)\n",
                                     "rand_fp = round(neg * pred_pos_rate)\n",
                                     "rand_fn = pos - rand_tp\n",
                                     "rand_tn = neg - rand_fp\n",
                                     "\n",
                                     "cm_rand = np.array([[rand_tp, rand_fn],\n",
                                     "                    [rand_fp, rand_tn]])\n",
                                     "print(\"Random classifier confusion matrix (matching positive rate):\")\n",
                                     "print(cm_rand)\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (d):** Matching the same 25% positive prediction rate gives the random-classifier confusion matrix `[[50, 150], [200, 600]]` (rows = Actual Default/No Default).\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "442f5fdf",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(e)** Calculate the overall **expected value (per person)** for the random classifier in step (d)."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "a5e6851c",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# --- Q3 (e) Expected value for random classifier ---\n",
                                     "ev_rand_total = float((cm_rand * benefit).sum())\n",
                                     "ev_rand_per_person = ev_rand_total / N\n",
                                     "print(f\"Expected value per person (random base): ${ev_rand_per_person:.4f}\")\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (e):** Plugging that matrix into the same payoffs gives an expected value of **-$6.00 per customer**, so the trained model is substantially better than random guessing.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "e344dc4c",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## 4) Question 4. [16 points]\n",
                                     "\n",
                                     "Two classifiers (**Model A** and **Model B**) are used to predict whether the **Fed Funds rate will increase** or not (class label: 1 = increase, 0 = no increase), with each quarter considered as an instance. The estimated probabilities of increase over the past 6 quarters by model A and B respectively are displayed in the following table:\n",
                                     "\n",
                                     "| Quarter | Actual Class | Model A | Model B |\n",
                                     "|:--:|:--:|:--:|:--:|\n",
                                     "| 0 | 1 | 0.43 | 0.63 |\n",
                                     "| 1 | 1 | 0.52 | 0.53 |\n",
                                     "| 2 | 1 | 0.85 | 0.56 |\n",
                                     "| 3 | 1 | 0.69 | 0.71 |\n",
                                     "| 4 | 0 | 0.03 | 0.18 |\n",
                                     "| 5 | 0 | 0.31 | 0.76 |\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "0a4b626b",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(a)** Plot the **ROC curve** for the 2 classifiers together with the **random classifier**. Please calculate the **TP** and **FP** rates with the following cutoff values **[0, 0.2, 0.4, 0.5, 0.6, 0.8, 1]** before plotting the ROC curve.  \n",
                                     "(**Note:** you may need to calculate each modelâ€™s TP and FP rates at each cut-off first. The visualization can be done with either manually or with Python.)\n",
                                     "\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "id":  "326bf1d6",
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "\n",
                                     "# --- Q4 ROC computation and plot ---\n",
                                     "y_true = np.array([1,1,1,1,0,0])\n",
                                     "pA = np.array([0.43, 0.52, 0.85, 0.69, 0.03, 0.31])\n",
                                     "pB = np.array([0.63, 0.53, 0.56, 0.71, 0.18, 0.76])\n",
                                     "\n",
                                     "cutoffs = [0, 0.2, 0.4, 0.5, 0.6, 0.8, 1]\n",
                                     "def tpr_fpr_at_cutoffs(y, p, cuts):\n",
                                     "    pts = []\n",
                                     "    pos = (y==1).sum()\n",
                                     "    neg = (y==0).sum()\n",
                                     "    for c in cuts:\n",
                                     "        yhat = (p \u003e= c).astype(int)\n",
                                     "        TP = ((yhat==1) \u0026 (y==1)).sum()\n",
                                     "        FP = ((yhat==1) \u0026 (y==0)).sum()\n",
                                     "        TPR = TP / pos if pos else 0.0\n",
                                     "        FPR = FP / neg if neg else 0.0\n",
                                     "        pts.append((FPR, TPR))\n",
                                     "    return np.array(pts)\n",
                                     "\n",
                                     "ptsA = tpr_fpr_at_cutoffs(y_true, pA, cutoffs)\n",
                                     "ptsB = tpr_fpr_at_cutoffs(y_true, pB, cutoffs)\n",
                                     "\n",
                                     "# Also compute AUC (continuous ROC using sklearn for reference)\n",
                                     "fprA, tprA, _ = roc_curve(y_true, pA)\n",
                                     "fprB, tprB, _ = roc_curve(y_true, pB)\n",
                                     "aucA = auc(fprA, tprA)\n",
                                     "aucB = auc(fprB, tprB)\n",
                                     "\n",
                                     "fig, ax = plt.subplots()\n",
                                     "ax.plot([0,1], [0,1], \u0027k--\u0027, label=\"Random\")\n",
                                     "ax.plot(ptsA[:,0], ptsA[:,1], \u0027o-\u0027, label=f\"Model A (AUC={aucA:.3f})\")\n",
                                     "ax.plot(ptsB[:,0], ptsB[:,1], \u0027o-\u0027, label=f\"Model B (AUC={aucB:.3f})\")\n",
                                     "ax.set_xlabel(\"False Positive Rate (1 - Specificity)\")\n",
                                     "ax.set_ylabel(\"True Positive Rate (Sensitivity)\")\n",
                                     "ax.set_title(\"ROC Curves at Specified Cutoffs\")\n",
                                     "ax.legend()\n",
                                     "plt.show()\n",
                                     "\n",
                                     "# Write your reasoning for (b) below this cell.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "id":  "d10604c9",
                      "source":  [
                                     "**Answer (a):** True/false-positive rates at the requested cutoffs (the random classifier lies on the $TPR = FPR$ diagonal shown in the ROC plot).",
                                     "",
                                     "| Cutoff | TP_A | FP_A | TPR_A | FPR_A | TP_B | FP_B | TPR_B | FPR_B |",
                                     "|---:|---:|---:|---:|---:|---:|---:|---:|---:|",
                                     "| 0.0 | 4 | 2 | 1.000 | 1.000 | 4 | 2 | 1.000 | 1.000 |",
                                     "| 0.2 | 4 | 1 | 1.000 | 0.500 | 4 | 1 | 1.000 | 0.500 |",
                                     "| 0.4 | 4 | 0 | 1.000 | 0.000 | 4 | 1 | 1.000 | 0.500 |",
                                     "| 0.5 | 3 | 0 | 0.750 | 0.000 | 4 | 1 | 1.000 | 0.500 |",
                                     "| 0.6 | 2 | 0 | 0.500 | 0.000 | 2 | 1 | 0.500 | 0.500 |",
                                     "| 0.8 | 1 | 0 | 0.250 | 0.000 | 0 | 0 | 0.000 | 0.000 |",
                                     "| 1.0 | 0 | 0 | 0.000 | 0.000 | 0 | 0 | 0.000 | 0.000 |",
                                     "",
                                     "Model A reaches the $(0,1)$ corner (TPR=1, FPR=0) while Model B falls back to the random line, matching the AUC comparison in part (b)."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "e50a6980",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**(b)** Which model is better? Why?"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "**Answer (b):** Model A strictly dominates Model B on the ROC curve (AUC 1.000 vs. 0.500), so Model A is better at every cutoff while Model B behaves like random guessing.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "f54bf68a",
                      "metadata":  {

                                   },
                      "source":  [
                                     "---\n",
                                     "\n",
                                     "### References / reminders (not graded)\n",
                                     "- Problem statements are transcribed from **Assignment 3**.  \n",
                                     "- This template mirrors the layout you used in Assignment 2 (section headers, environment setup, and code stubs), but **no solutions are provided**."
                                 ]
                  }
              ],
    "metadata":  {
                     "language_info":  {
                                           "name":  "python"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
