{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN for Credit Decisions and Profit Maximization\n",
        "\n",
        "*Auto-generated on 2025-11-12T09:28:25*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Environment setup (optional)\n",
        "If you get errors reading `.xls`, run the cell below to install dependencies. Comment it out if you don't need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: install extra dependencies if needed\n",
        "# Use only if you get import errors for xlrd or imbalanced-learn\n",
        "# %pip install -q xlrd imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Executive Summary (objective + deliverables)\n",
        "**Objective.** Train and validate a supervised KNN classifier to estimate applicants' default probability and make approve/decline decisions that **maximize expected profit** under a business cost/benefit matrix.  \n",
        "**Deliverables.** 1) KNN model encapsulated in a reproducible pipeline, 2) operating threshold optimized for utility, 3) holdout test evaluation with technical metrics and **business utility**, 4) deployment and monitoring guidelines.  \n",
        "**Success criterion.** Beat baselines (approve all / approve none) in net utility; keep risk metrics aligned with policy (e.g., minimum TPR on a priority segment).  \n",
        "**Key assumptions.** Use case: credit decision for existing customers (historical information available) with target \"default next period.\" Costs and benefits are provided by the business (or scenario-based here).  \n",
        "**Limitations.** KNN is sensitive to scaling, dimensionality, and inference latency; mitigated via preprocessing, k selection, and production controls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versions -> pandas: 2.2.3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report, brier_score_loss\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import calibration_curve\n",
        "import joblib\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "print(\"Versions -> pandas:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration (paths and business parameters)\n",
        "Update `DATA_PATH` or `GITHUB_RAW_URL` if needed. Business costs/benefits are scenario placeholders; replace with real values when available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data source configuration\n",
        "DATA_PATH = \"default of credit card clients.xls\"  # local path\n",
        "GITHUB_RAW_URL = \"\"  # e.g., \"https://raw.githubusercontent.com/<user>/<repo>/<branch>/path/to/file.xls\"\n",
        "\n",
        "# Target and basic options\n",
        "TARGET_CANDIDATES = [\n",
        "    \"default.payment.next.month\", \n",
        "    \"default_payment_next_month\", \n",
        "    \"Y\", \"DEFAULT\", \"DEFAULT_NEXT_MONTH\"\n",
        "]\n",
        "\n",
        "ID_CANDIDATES = [\"ID\", \"Id\", \"id\"]\n",
        "\n",
        "# Business utility parameters (placeholder scenario). Replace with real values.\n",
        "# Utility = TP*B_TP - FP*C_FP - FN*C_FN + TN*B_TN\n",
        "BUSINESS_PARAMS = {\n",
        "    \"B_TP\": 1.0,   # benefit of approving a non-defaulter\n",
        "    \"C_FP\": 5.0,   # cost of approving a defaulter\n",
        "    \"C_FN\": 0.3,   # opportunity cost of rejecting a good customer\n",
        "    \"B_TN\": 0.0    # benefit of rejecting a defaulter (could be 0 or small positive)\n",
        "}\n",
        "\n",
        "RANDOM_STATE = 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data loading and sanitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to read Excel: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xlrd'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, url)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxlrd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# xls needs xlrd\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:45\u001b[39m, in \u001b[36mXlrdReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m err_msg = \u001b[33m\"\u001b[39m\u001b[33mInstall xlrd >= 2.0.1 for xls Excel support\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxlrd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     47\u001b[39m     filepath_or_buffer,\n\u001b[32m     48\u001b[39m     storage_options=storage_options,\n\u001b[32m     49\u001b[39m     engine_kwargs=engine_kwargs,\n\u001b[32m     50\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xlrd'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, url)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# try default/openpyxl for xlsx\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:45\u001b[39m, in \u001b[36mXlrdReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m err_msg = \u001b[33m\"\u001b[39m\u001b[33mInstall xlrd >= 2.0.1 for xls Excel support\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxlrd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     47\u001b[39m     filepath_or_buffer,\n\u001b[32m     48\u001b[39m     storage_options=storage_options,\n\u001b[32m     49\u001b[39m     engine_kwargs=engine_kwargs,\n\u001b[32m     50\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m     df = _standardize_columns(df)\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m df_raw = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGITHUB_RAW_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRaw shape:\u001b[39m\u001b[33m\"\u001b[39m, df_raw.shape)\n\u001b[32m     62\u001b[39m display(df_raw.head())\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, url)\u001b[39m\n\u001b[32m     45\u001b[39m             df = pd.read_excel(src)  \u001b[38;5;66;03m# try default/openpyxl for xlsx\u001b[39;00m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to read Excel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     49\u001b[39m     df = pd.read_csv(src)\n",
            "\u001b[31mRuntimeError\u001b[39m: Failed to read Excel: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd."
          ]
        }
      ],
      "source": [
        "def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Normalize column names: lower, underscores, no dots, no spaces\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "          .str.strip()\n",
        "          .str.replace(r\"[^\\w\\s\\-\\.]\", \"\", regex=True)\n",
        "          .str.replace(r\"\\s+\", \"_\", regex=True)\n",
        "          .str.replace(r\"\\.+\", \"_\", regex=True)\n",
        "          .str.lower()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def _find_target(df: pd.DataFrame, candidates=TARGET_CANDIDATES) -> str:\n",
        "    cols = set(df.columns)\n",
        "    for c in candidates:\n",
        "        c1 = c.lower().replace(\".\", \"_\")\n",
        "        if c1 in cols:\n",
        "            return c1\n",
        "    raise KeyError(f\"Target not found. Candidates: {candidates}. Available: {list(df.columns)[:10]} ...\")\n",
        "\n",
        "def _find_id(df: pd.DataFrame, candidates=ID_CANDIDATES) -> str | None:\n",
        "    cols = set(df.columns)\n",
        "    for c in candidates:\n",
        "        c1 = c.lower()\n",
        "        if c1 in cols:\n",
        "            return c1\n",
        "    return None\n",
        "\n",
        "def load_dataset(path: str = None, url: str = None) -> pd.DataFrame:\n",
        "    if url and url.strip():\n",
        "        src = url.strip()\n",
        "    elif path and os.path.exists(path):\n",
        "        src = path\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No valid data source. Set DATA_PATH or GITHUB_RAW_URL.\")\n",
        "\n",
        "    ext = os.path.splitext(src)[1].lower()\n",
        "    if ext in [\".xls\", \".xlsx\"]:\n",
        "        # Try reading excel with fallback engines\n",
        "        try:\n",
        "            df = pd.read_excel(src, engine=\"xlrd\")  # xls needs xlrd\n",
        "        except Exception:\n",
        "            try:\n",
        "                df = pd.read_excel(src)  # try default/openpyxl for xlsx\n",
        "            except Exception as e:\n",
        "                raise RuntimeError(f\"Failed to read Excel: {e}\")\n",
        "    elif ext in [\".csv\"]:\n",
        "        df = pd.read_csv(src)\n",
        "    else:\n",
        "        # Try read_excel by default; if fails, try read_csv\n",
        "        try:\n",
        "            df = pd.read_excel(src)\n",
        "        except Exception:\n",
        "            df = pd.read_csv(src)\n",
        "\n",
        "    df = _standardize_columns(df)\n",
        "    return df\n",
        "\n",
        "df_raw = load_dataset(DATA_PATH, GITHUB_RAW_URL)\n",
        "print(\"Raw shape:\", df_raw.shape)\n",
        "display(df_raw.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Basic EDA and target preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify target and ID\n",
        "target_col = _find_target(df_raw)\n",
        "id_col = _find_id(df_raw)\n",
        "\n",
        "print(\"Target column:\", target_col, \"| ID column:\", id_col)\n",
        "\n",
        "# Remove ID if present\n",
        "df = df_raw.copy()\n",
        "if id_col is not None and id_col in df.columns:\n",
        "    df = df.drop(columns=[id_col])\n",
        "\n",
        "# Ensure binary target is int {0,1}\n",
        "if df[target_col].dtype != int and df[target_col].dtype != \"int64\":\n",
        "    df[target_col] = df[target_col].astype(int)\n",
        "\n",
        "y = df[target_col].values\n",
        "X = df.drop(columns=[target_col])\n",
        "\n",
        "print(\"Prepared shape -> X:\", X.shape, \" y:\", y.shape)\n",
        "print(\"Default rate (mean of target):\", y.mean())\n",
        "display(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature schema and preprocessing pipeline\n",
        "One-hot for categorical codes (SEX, EDUCATION, MARRIAGE). Ordinal-like variables (PAY_0..PAY_6) and continuous amounts are treated as numeric and scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Candidate categorical variables (encoded as small integers but represent categories)\n",
        "candidate_cats = [c for c in [\"sex\", \"education\", \"marriage\"] if c in X.columns]\n",
        "\n",
        "# Numeric = all others\n",
        "numeric_cols = [c for c in X.columns if c not in candidate_cats]\n",
        "\n",
        "print(\"Categorical:\", candidate_cats)\n",
        "print(\"Numeric (first 10):\", numeric_cols[:10], \"... total:\", len(numeric_cols))\n",
        "\n",
        "preprocess = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(with_mean=True, with_std=True), numeric_cols),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), candidate_cats)\n",
        "], remainder=\"drop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train/Validation/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# From train_val, carve validation set (20% of the original data -> val_size=0.25 of train_val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=RANDOM_STATE, stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. KNN model and hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"knn\", knn)\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"knn__n_neighbors\": [5, 11, 21, 31],\n",
        "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
        "    \"knn__p\": [1, 2]  # Manhattan vs Euclidean\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "gs = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"roc_auc\",   # technical metric for model selection\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"Best CV ROC-AUC:\", round(gs.best_score_, 4))\n",
        "\n",
        "best_model = gs.best_estimator_\n",
        "# Evaluate on validation set (probabilities)\n",
        "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print(\"Val ROC-AUC:\", round(roc_auc_score(y_val, y_val_proba), 4))\n",
        "print(\"Val PR-AUC:\", round(average_precision_score(y_val, y_val_proba), 4))\n",
        "print(\"Val Brier:\", round(brier_score_loss(y_val, y_val_proba), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Utility function and threshold optimization on validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_counts(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn, fp, fn, tp\n",
        "\n",
        "def utility_from_counts(tn, fp, fn, tp, params=BUSINESS_PARAMS):\n",
        "    return (tp * params[\"B_TP\"]) - (fp * params[\"C_FP\"]) - (fn * params[\"C_FN\"]) + (tn * params[\"B_TN\"])\n",
        "\n",
        "def classify_with_threshold(proba, thr):\n",
        "    return (proba >= thr).astype(int)\n",
        "\n",
        "def find_tau_star(y_true, proba, params=BUSINESS_PARAMS, grid=None):\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.0, 1.0, 1001)\n",
        "    best_thr, best_u = None, -np.inf\n",
        "    for t in grid:\n",
        "        yhat = classify_with_threshold(proba, t)\n",
        "        tn, fp, fn, tp = confusion_counts(y_true, yhat)\n",
        "        u = utility_from_counts(tn, fp, fn, tp, params)\n",
        "        if u > best_u:\n",
        "            best_u = u\n",
        "            best_thr = t\n",
        "    return best_thr, best_u\n",
        "\n",
        "tau_star, U_val = find_tau_star(y_val, y_val_proba, BUSINESS_PARAMS)\n",
        "print(\"Optimal threshold (tau*):\", round(float(tau_star), 4), \"| Val Utility:\", round(float(U_val), 4))\n",
        "\n",
        "# Baselines (on validation using ground truth counts)\n",
        "n_default = int(y_val.sum())\n",
        "n_nondefault = int((1 - y_val).sum())\n",
        "U_approve_all = (n_nondefault * BUSINESS_PARAMS[\"B_TP\"]) - (n_default * BUSINESS_PARAMS[\"C_FP\"])\n",
        "U_reject_all = (n_default * BUSINESS_PARAMS[\"B_TN\"]) - (n_nondefault * BUSINESS_PARAMS[\"C_FN\"])\n",
        "\n",
        "print(\"Baseline (approve all):\", round(float(U_approve_all), 4))\n",
        "print(\"Baseline (reject all):\", round(float(U_reject_all), 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Final evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "y_test_hat = classify_with_threshold(y_test_proba, tau_star)\n",
        "\n",
        "tn, fp, fn, tp = confusion_counts(y_test, y_test_hat)\n",
        "U_test = utility_from_counts(tn, fp, fn, tp, BUSINESS_PARAMS)\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "pr_auc = average_precision_score(y_test, y_test_proba)\n",
        "\n",
        "print(\"Test ROC-AUC:\", round(roc_auc, 4), \"| Test PR-AUC:\", round(pr_auc, 4))\n",
        "print(\"Confusion matrix [tn, fp, fn, tp]:\", [tn, fp, fn, tp])\n",
        "print(\"Test Utility:\", round(float(U_test), 4))\n",
        "\n",
        "# Baselines on test\n",
        "n_default_test = int(y_test.sum())\n",
        "n_nondefault_test = int((1 - y_test).sum())\n",
        "U_test_approve_all = (n_nondefault_test * BUSINESS_PARAMS[\"B_TP\"]) - (n_default_test * BUSINESS_PARAMS[\"C_FP\"])\n",
        "U_test_reject_all = (n_default_test * BUSINESS_PARAMS[\"B_TN\"]) - (n_nondefault_test * BUSINESS_PARAMS[\"C_FN\"])\n",
        "\n",
        "print(\"Baseline Test (approve all):\", round(float(U_test_approve_all), 4))\n",
        "print(\"Baseline Test (reject all):\", round(float(U_test_reject_all), 4))\n",
        "\n",
        "print(\"\\nClassification report (thresholded):\\n\", classification_report(y_test, y_test_hat, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Probability calibration check (no plots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibration via Brier score (already printed for val); here for test:\n",
        "brier = brier_score_loss(y_test, y_test_proba)\n",
        "print(\"Test Brier score:\", round(brier, 4))\n",
        "\n",
        "# Optional: compute calibration curve points\n",
        "prob_true, prob_pred = calibration_curve(y_test, y_test_proba, n_bins=10, strategy=\"uniform\")\n",
        "calibration_table = pd.DataFrame({\"mean_predicted\": prob_pred, \"fraction_of_positives\": prob_true})\n",
        "display(calibration_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Local interpretability: nearest neighbors for one test applicant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll inspect neighbors for one test sample\n",
        "sample_ix = 0\n",
        "xq = X_test.iloc[[sample_ix]]\n",
        "yq = y_test[sample_ix]\n",
        "\n",
        "# Transform features\n",
        "pre = best_model.named_steps[\"prep\"]\n",
        "knn_est = best_model.named_steps[\"knn\"]\n",
        "xq_t = pre.transform(xq)\n",
        "\n",
        "# Distances and indices among the training set used by KNN\n",
        "dists, idxs = knn_est.kneighbors(xq_t, n_neighbors=min(knn_est.n_neighbors, len(X_train)))\n",
        "\n",
        "# Show neighbors (map indices to the training DataFrame index)\n",
        "neighbors_info = []\n",
        "for d, i in zip(dists[0], idxs[0]):\n",
        "    # The indices returned correspond to the order used internally (fit on transformed X_train)\n",
        "    # We'll reconstruct by transforming X_train to ensure alignment of indices\n",
        "    # Note: KNN stores training samples internally; to fetch the original row, use the position i\n",
        "    orig_row = X_train.iloc[i].to_dict()\n",
        "    orig_row[\"__distance__\"] = float(d)\n",
        "    orig_row[\"__y_train__\"] = int(y_train[i])\n",
        "    neighbors_info.append(orig_row)\n",
        "\n",
        "neighbors_df = pd.DataFrame(neighbors_info)\n",
        "display(pd.DataFrame({\n",
        "    \"query_true_label\": [int(yq)],\n",
        "    \"n_neighbors\": [knn_est.n_neighbors]\n",
        "}))\n",
        "display(neighbors_df.sort_values(\"__distance__\").head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Export artifacts (pipeline and config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ARTIFACT_DIR = \"artifacts\"\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "PIPELINE_PATH = os.path.join(ARTIFACT_DIR, \"knn_credit_pipeline.joblib\")\n",
        "CONFIG_PATH = os.path.join(ARTIFACT_DIR, \"knn_credit_config.json\")\n",
        "\n",
        "joblib.dump({\n",
        "    \"model\": best_model,\n",
        "    \"features_numeric\": best_model.named_steps[\"prep\"].transformers_[0][2],\n",
        "    \"features_categorical\": best_model.named_steps[\"prep\"].transformers_[1][2],\n",
        "    \"params\": gs.best_params_,\n",
        "}, PIPELINE_PATH)\n",
        "\n",
        "with open(CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\n",
        "        \"BUSINESS_PARAMS\": BUSINESS_PARAMS,\n",
        "        \"tau_star\": float(tau_star),\n",
        "        \"random_state\": RANDOM_STATE\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"Saved pipeline ->\", PIPELINE_PATH)\n",
        "print(\"Saved config   ->\", CONFIG_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Conclusions and next steps\n",
        "- KNN performance reported with ROC/PR and **business utility**.\n",
        "- Operating threshold selected via **utility maximization** on validation.\n",
        "- Replace placeholder BUSINESS_PARAMS with real costs/benefits; re-run threshold search.\n",
        "- For production, profile latency and memory; consider approximate neighbors or a more scalable model if needed."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
