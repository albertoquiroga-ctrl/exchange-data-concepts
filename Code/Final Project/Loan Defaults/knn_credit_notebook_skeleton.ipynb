{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# KNN for Credit Decisions and Profit Maximization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. Executive Summary (objective + deliverables)\n**Objective.** Train and validate a supervised KNN classifier to estimate applicants' default probability and make approve/decline decisions that **maximize expected profit** under a business cost/benefit matrix.  \n**Deliverables.** 1) KNN model encapsulated in a reproducible pipeline, 2) operating threshold optimized for utility, 3) holdout test evaluation with technical metrics and **business utility**, 4) deployment and monitoring guidelines.  \n**Success criterion.** Beat baselines (approve all / approve none) in net utility; keep risk metrics aligned with policy (e.g., minimum TPR on a priority segment).  \n**Key assumptions.** Use case: credit decision for existing customers (historical information available) with target \"default next period.\" Costs and benefits are provided by the business (or scenario-based here).  \n**Limitations.** KNN is sensitive to scaling, dimensionality, and inference latency; mitigated via preprocessing, k selection, and production controls."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Context and Sources\n### 1.1. Problem statement\nAt application time, the bank wants a system that **predicts default risk** and decides approve/decline to maximize financial utility. The decision depends on: estimated risk, operating threshold, and the cost/benefit matrix.\n\n### 1.2. Dataset and data dictionary\n\"Default of Credit Card Clients\" (~30k rows). Demographics, credit limit, recent payment history, billed amounts, and previous payments. Binary label: `default_payment_next_month` (1=default, 0=no default).  \nVariable groups:  \n- Demographics/profile: `LIMIT_BAL`, `SEX`, `EDUCATION`, `MARRIAGE`, `AGE`.  \n- Payment history: `PAY_0` ... `PAY_6` (recent monthly status).  \n- Billed amounts: `BILL_AMT1` ... `BILL_AMT6`.  \n- Paid amounts: `PAY_AMT1` ... `PAY_AMT6`.  \n- Target: `default_payment_next_month`.\n\n### 1.3. Link to the course\nApply Similarity and Neighbors (KNN) concepts: effect of scaling, distance metric choice, k selection, probability calibration, and decision thresholds."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.base import clone\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    make_scorer,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_predict,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "pd.set_option(\"display.float_format\", lambda v: f\"{v:,.2f}\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"Code\" / \"Final Project\" / \"Loan Defaults\"\n",
    "DATA_FILE = DATA_DIR / \"default of credit card clients.xls\"\n",
    "TARGET = \"default_payment_next_month\"\n",
    "ID_COLS = [\"ID\"]\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "raw_df = (\n",
    "    pd.read_excel(DATA_FILE, header=1)\n",
    "    .rename(columns={\"default payment next month\": TARGET})\n",
    ")\n",
    "raw_df[TARGET] = raw_df[TARGET].astype(int)\n",
    "\n",
    "print(f\"Rows: {raw_df.shape[0]:,} | Columns: {raw_df.shape[1]}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Business Metric Design\n### 2.1. Cost/benefit matrix (TP, FP, TN, FN)\nDefinitions:  \n- **TP**: approve a non-defaulter → benefit = expected margin (interest − cost of funds − provisions) minus operating costs.  \n- **FP**: approve a defaulter → cost = expected loss (principal × LGD − recoveries) + expenses.  \n- **TN**: reject a defaulter → benefit/cost ≈ 0, or benefit from avoided losses.  \n- **FN**: reject a good customer → opportunity cost (foregone margin).\n\n### 2.2. Expected value function and optimal decision threshold\nFor estimated default probability $\\\\hat{p}$, expected **utility** of approval is:\n$$\nU(\\\\text{approve}) = (1-\\\\hat{p}) \\\\cdot B_{\\\\text{TP}} - \\\\hat{p} \\\\cdot C_{\\\\text{FP}}\n$$\nand of **reject**:\n$$\nU(\\\\text{reject}) = (1-\\\\hat{p}) \\\\cdot (-C_{\\\\text{FN}}) + \\\\hat{p} \\\\cdot B_{\\\\text{TN}}\n$$\nDefine the **optimal threshold** $\\\\tau^*$ such that approve if $U(\\\\text{approve}) \\\\ge U(\\\\text{reject})$. This threshold is not necessarily 0.5 and depends on the cost/benefit matrix.\n\n### 2.3. Reference baselines\n- **Approve all**: utility if nobody is rejected.  \n- **Reject all**: utility if nobody is approved.  \nThe model must **outperform** both in utility."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COST_MATRIX = {\n",
    "    \"tp_benefit\": 1600,\n",
    "    \"fp_cost\": 6000,\n",
    "    \"fn_cost\": 1200,\n",
    "    \"tn_benefit\": 200,\n",
    "}\n",
    "THRESHOLD_GRID = np.linspace(0.05, 0.95, 181)\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return {\n",
    "        \"tp\": int(np.sum((y_true == 1) & (y_pred == 1))),\n",
    "        \"fp\": int(np.sum((y_true == 0) & (y_pred == 1))),\n",
    "        \"tn\": int(np.sum((y_true == 0) & (y_pred == 0))),\n",
    "        \"fn\": int(np.sum((y_true == 1) & (y_pred == 0))),\n",
    "    }\n",
    "\n",
    "def cost_sensitive_utility(counts, matrix=COST_MATRIX, normalize=False):\n",
    "    utility = (\n",
    "        counts[\"tp\"] * matrix[\"tp_benefit\"]\n",
    "        + counts[\"tn\"] * matrix[\"tn_benefit\"]\n",
    "        - counts[\"fp\"] * matrix[\"fp_cost\"]\n",
    "        - counts[\"fn\"] * matrix[\"fn_cost\"]\n",
    "    )\n",
    "    if normalize:\n",
    "        total = sum(counts.values())\n",
    "        return utility / total\n",
    "    return utility\n",
    "\n",
    "def evaluate_predictions(y_true, y_prob, threshold, matrix=COST_MATRIX):\n",
    "    preds = (y_prob >= threshold).astype(int)\n",
    "    counts = confusion_counts(y_true, preds)\n",
    "    utility = cost_sensitive_utility(counts, matrix=matrix, normalize=False)\n",
    "    return {\n",
    "        \"threshold\": threshold,\n",
    "        \"utility\": utility,\n",
    "        \"normalized_utility\": utility / len(y_true),\n",
    "        **counts,\n",
    "    }\n",
    "\n",
    "def search_best_threshold(y_true, y_prob, matrix=COST_MATRIX, grid=THRESHOLD_GRID):\n",
    "    rows = [evaluate_predictions(y_true, y_prob, tau, matrix) for tau in grid]\n",
    "    results = pd.DataFrame(rows)\n",
    "    best_row = results.loc[results[\"utility\"].idxmax()].to_dict()\n",
    "    return results, best_row\n",
    "\n",
    "def normalized_best_utility(y_true, y_prob):\n",
    "    _, best_row = search_best_threshold(y_true, y_prob)\n",
    "    return best_row[\"normalized_utility\"]\n",
    "\n",
    "utility_scorer = make_scorer(normalized_best_utility, needs_proba=True, greater_is_better=True)\n",
    "\n",
    "print(\"Cost/Benefit matrix:\", COST_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Data Understanding (targeted EDA)\n### 3.1. Target distribution\nDefault is typically imbalanced. Document prevalence and implications for metrics (accuracy can mislead; prefer ROC/PR and utility).\n\n### 3.2. Variable types\nIdentify: continuous numeric (limits, amounts), ordinal (payment status), encoded categorical (sex, education, marital status). Justify treatment given the distance metric.\n\n### 3.3. Missing values and outliers\nState policies: minimal imputation if needed; winsorization or robust scaling to reduce outlier impact on distances.\n\n### 3.4. Correlations and scales\nKNN requires **scaling** so large-range variables don't dominate distance. Document StandardScaler/RobustScaler choice and rationale."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = (\n",
    "    raw_df[TARGET]\n",
    "    .value_counts()\n",
    "    .rename_axis(\"default\")\n",
    "    .reset_index(name=\"count\")\n",
    "    .assign(pct=lambda df: df[\"count\"] / df[\"count\"].sum())\n",
    ")\n",
    "\n",
    "missing = raw_df.isna().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "pay_cols = [c for c in raw_df.columns if c.startswith(\"PAY_\")]\n",
    "corr_cols = pay_cols + [\"LIMIT_BAL\", TARGET]\n",
    "corr_matrix = raw_df[corr_cols].corr(method=\"spearman\")\n",
    "\n",
    "display(target_counts)\n",
    "if not missing.empty:\n",
    "    display(missing.to_frame(\"missing_values\"))\n",
    "\n",
    "display(raw_df.describe().T[[\"mean\", \"std\", \"min\", \"max\"]].round(2).head(10))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "sns.barplot(data=target_counts, x=\"default\", y=\"pct\", ax=axes[0])\n",
    "axes[0].set_title(\"Target distribution\")\n",
    "axes[0].set_ylabel(\"Prevalence\")\n",
    "\n",
    "sns.boxplot(data=raw_df, y=\"LIMIT_BAL\", ax=axes[1])\n",
    "axes[1].set_title(\"LIMIT_BAL spread\")\n",
    "\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", center=0, ax=axes[2])\n",
    "axes[2].set_title(\"Spearman correlation snapshot\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Avoid Leakage and Define the Feature Set\n### 4.1. Inclusion/exclusion criteria\nUse only variables **available at decision time**. Exclude any that anticipate the outcome beyond the defined horizon.\n\n### 4.2. Transformations/encoding\n- Categoricals: consistent encoding for KNN (one-hot if needed).  \n- Ordinal variables: preserve order when meaningful (payment status).  \n- Amounts: consider log or robust transforms for heavy tails.\n\n### 4.3. Candidate feature list\nDemographics/profile + recent payment history + billed and paid amounts prior to the decision cutoff. Document exclusions due to leakage or low signal."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "numeric_features = [\n",
    "    col for col in raw_df.columns\n",
    "    if col not in ID_COLS + [TARGET] + categorical_features\n",
    "]\n",
    "\n",
    "feature_overview = pd.DataFrame({\n",
    "    \"feature\": numeric_features + categorical_features,\n",
    "    \"type\": [\"numeric\"] * len(numeric_features) + [\"categorical\"] * len(categorical_features),\n",
    "})\n",
    "\n",
    "display(feature_overview.head(12))\n",
    "print(f\"Total candidate features: {len(feature_overview)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Data Split and Validation Protocol\n### 5.1. Train/validation/test\nStratified splitting to preserve target prevalence. Hold out test for final evaluation.\n\n### 5.2. Validation metrics\nReport ROC-AUC and PR-AUC for general performance; **optimize and report expected utility** per the business matrix.\n\n### 5.3. Repeats/seed for stability\nUse multiple seeds or stratified CV; report mean and dispersion for robustness."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_df.drop(columns=ID_COLS + [TARGET])\n",
    "y = raw_df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]:,} | Test size: {X_test.shape[0]:,}\")\n",
    "print(f\"Train default rate: {y_train.mean():.3f} | Test default rate: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Preprocessing and Pipeline\n### 6.1. Scaling\nInclude scaling inside the pipeline to avoid information leakage across splits.\n\n### 6.2. Encoding\nApply categorical encoding inside the pipeline, consistent across train and test.\n\n### 6.3. Pipeline structure\n[coherent preprocessing] -> [scaling] -> [KNNClassifier]. Document decisions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, numeric_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. KNN Modeling (supervised classification)\n### 7.1. Hyperparameters to tune\n- n_neighbors (k): controls boundary smoothness and variance.  \n- weights: uniform vs distance.  \n- p: 1 (Manhattan) vs 2 (Euclidean).  \n- metric, leaf_size as needed.\n\n### 7.2. Hyperparameter search\nGrid/Random search with stratified CV. Primary optimization: **utility**; secondary metrics: ROC-AUC/PR-AUC.\n\n### 7.3. Performance vs k curve\nDocument bias-variance trade-off and how utility changes with k."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"knn\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [11, 21, 31, 41],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__p\": [1, 2],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=knn_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring={\"utility\": utility_scorer, \"roc_auc\": \"roc_auc\", \"pr_auc\": \"average_precision\"},\n",
    "    refit=\"utility\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "cv_results = (\n",
    "    pd.DataFrame(grid.cv_results_)\n",
    "    .sort_values(by=\"mean_test_utility\", ascending=False)\n",
    "    .loc[:, [\n",
    "        \"param_knn__n_neighbors\",\n",
    "        \"param_knn__weights\",\n",
    "        \"param_knn__p\",\n",
    "        \"mean_test_utility\",\n",
    "        \"mean_test_roc_auc\",\n",
    "        \"mean_test_pr_auc\",\n",
    "    ]]\n",
    ")\n",
    "\n",
    "display(cv_results.head(8))\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(f\"Best normalized utility (cv): {grid.best_score_:.4f}\")\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Probabilities, Calibration, and Utility-Based Threshold\n### 8.1. Probability prediction and calibration\nKNN probabilities come from the positive fraction among neighbors. Assess **calibration** and, if necessary, apply calibration (Platt/Isotonic) on a validation set.\n\n### 8.2. Utility vs threshold curve\nConstruct the utility curve by varying the decision threshold. Explain how the maximum is selected.\n\n### 8.3. Operating threshold selection\nChoose $\\\\tau^*$ that maximizes utility. If business imposes constraints (e.g., minimum TPR), select the best threshold that satisfies them."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs = cross_val_predict(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    method=\"predict_proba\",\n",
    "    n_jobs=-1,\n",
    ")[:, 1]\n",
    "\n",
    "threshold_curve, best_threshold_row = search_best_threshold(y_train, oof_probs)\n",
    "best_threshold = float(best_threshold_row[\"threshold\"])\n",
    "\n",
    "print(f\"Best threshold (utility-optimized): {best_threshold:.3f}\")\n",
    "print(f\"Normalized utility at tau*: {best_threshold_row['normalized_utility']:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "axes[0].plot(threshold_curve[\"threshold\"], threshold_curve[\"normalized_utility\"], label=\"Utility/customer\")\n",
    "axes[0].axvline(best_threshold, color=\"red\", linestyle=\"--\", label=f\"tau*={best_threshold:.2f}\")\n",
    "axes[0].set_xlabel(\"Threshold\")\n",
    "axes[0].set_ylabel(\"Normalized utility\")\n",
    "axes[0].legend()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_train, oof_probs)\n",
    "axes[1].plot(fpr, tpr, label=f\"ROC AUC={roc_auc_score(y_train, oof_probs):.3f}\")\n",
    "axes[1].plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"False positive rate\")\n",
    "axes[1].set_ylabel(\"True positive rate\")\n",
    "axes[1].set_title(\"Training ROC (OOF)\")\n",
    "axes[1].legend()\n",
    "\n",
    "CalibrationDisplay.from_predictions(\n",
    "    y_train,\n",
    "    oof_probs,\n",
    "    n_bins=10,\n",
    "    strategy=\"quantile\",\n",
    "    ax=axes[2],\n",
    ")\n",
    "axes[2].set_title(\"Calibration (OOF)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Final Evaluation and Baselines\n### 9.1. Primary metrics\nROC-AUC, PR-AUC, confusion matrix on test, and **total utility** vs baselines.\n\n### 9.2. Utility by segments\nAnalyze utility by relevant subgroups (limits, tenure, internal score) to confirm consistency of benefit.\n\n### 9.3. Stability\nVariation across folds/seeds. Note if the model is sensitive to small perturbations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "test_preds = (test_probs >= best_threshold).astype(int)\n",
    "test_counts = confusion_counts(y_test, test_preds)\n",
    "test_utility = cost_sensitive_utility(test_counts, matrix=COST_MATRIX, normalize=False)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, test_probs)\n",
    "pr_auc = average_precision_score(y_test, test_probs)\n",
    "\n",
    "print(f\"Test ROC-AUC: {roc_auc:.3f} | PR-AUC: {pr_auc:.3f}\")\n",
    "print(f\"Test utility (total): {test_utility:,.0f} | per customer: {test_utility / len(y_test):.2f}\")\n",
    "print(classification_report(y_test, test_preds, digits=3))\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_test, test_preds),\n",
    "    index=pd.Index([\"Actual 0\", \"Actual 1\"], name=\"Actual\"),\n",
    "    columns=pd.Index([\"Pred 0\", \"Pred 1\"], name=\"Predicted\"),\n",
    ")\n",
    "display(cm)\n",
    "\n",
    "baseline_preds = {\n",
    "    \"approve_all\": np.ones_like(y_test),\n",
    "    \"reject_all\": np.zeros_like(y_test),\n",
    "    \"threshold_0.50\": (test_probs >= 0.5).astype(int),\n",
    "}\n",
    "baseline_rows = []\n",
    "for name, preds in baseline_preds.items():\n",
    "    counts = confusion_counts(y_test, preds)\n",
    "    util = cost_sensitive_utility(counts, matrix=COST_MATRIX, normalize=True)\n",
    "    baseline_rows.append({\n",
    "        \"strategy\": name,\n",
    "        \"normalized_utility\": util,\n",
    "        \"tp\": counts[\"tp\"],\n",
    "        \"fp\": counts[\"fp\"],\n",
    "        \"tn\": counts[\"tn\"],\n",
    "        \"fn\": counts[\"fn\"],\n",
    "    })\n",
    "baseline_df = pd.DataFrame(baseline_rows).sort_values(\"normalized_utility\", ascending=False)\n",
    "display(baseline_df)\n",
    "\n",
    "test_results = X_test.copy()\n",
    "test_results[\"y_true\"] = y_test.values\n",
    "test_results[\"prob_default\"] = test_probs\n",
    "test_results[\"y_pred\"] = test_preds\n",
    "test_results[\"limit_segment\"] = pd.qcut(test_results[\"LIMIT_BAL\"], q=4, duplicates=\"drop\").astype(str)\n",
    "\n",
    "segment_summary = []\n",
    "for seg, df_seg in test_results.groupby(\"limit_segment\"):\n",
    "    counts = confusion_counts(df_seg[\"y_true\"], df_seg[\"y_pred\"])\n",
    "    seg_util = cost_sensitive_utility(counts, normalize=True)\n",
    "    segment_summary.append({\n",
    "        \"limit_segment\": seg,\n",
    "        \"customers\": len(df_seg),\n",
    "        \"default_rate\": df_seg[\"y_true\"].mean(),\n",
    "        \"utility_per_customer\": seg_util,\n",
    "    })\n",
    "segment_summary = pd.DataFrame(segment_summary).sort_values(\"utility_per_customer\", ascending=False)\n",
    "display(segment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Error and Sensitivity Analysis\n### 10.1. Sensitivity to k, metric, and scaling\nDocument how results change with k, p, and scaling type.\n\n### 10.2. Dimensionality and noise\nExplain the effect of irrelevant variables on KNN and why filtering or weighting helps.\n\n### 10.3. Business-critical errors\nIdentify the most financially costly FP/FN; propose complementary rules (e.g., exposure caps by segment)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_summary = (\n",
    "    pd.DataFrame(grid.cv_results_)\n",
    "    .groupby(\"param_knn__n_neighbors\")[[\"mean_test_utility\", \"mean_test_roc_auc\", \"mean_test_pr_auc\"]]\n",
    "    .agg(['mean', 'std'])\n",
    ")\n",
    "cv_summary.columns = ['_'.join(col).strip() for col in cv_summary.columns]\n",
    "cv_summary = cv_summary.reset_index().rename(columns={\"param_knn__n_neighbors\": \"k\"})\n",
    "\n",
    "display(cv_summary)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(cv_summary[\"k\"], cv_summary[\"mean_test_utility_mean\"], marker=\"o\")\n",
    "plt.fill_between(\n",
    "    cv_summary[\"k\"],\n",
    "    cv_summary[\"mean_test_utility_mean\"] - cv_summary[\"mean_test_utility_std\"],\n",
    "    cv_summary[\"mean_test_utility_mean\"] + cv_summary[\"mean_test_utility_std\"],\n",
    "    color=\"C0\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.title(\"Utility sensitivity vs k\")\n",
    "plt.xlabel(\"k (neighbors)\")\n",
    "plt.ylabel(\"Normalized utility\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Local Interpretability for KNN Decisions\n### 11.1. Nearest neighbors\nFor one applicant, show key attributes and distances of the k neighbors. Explain the local reason for approval or rejection.\n\n### 11.2. Traceability\nKeep a record of consulted neighbors and key variables for auditability.\n\n### 11.3. Limitations\nKNN lacks global coefficients; explanations are **local** and neighborhood-dependent."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = test_results[\"prob_default\"].idxmax()\n",
    "sample_x = X_test.loc[[sample_idx]]\n",
    "sample_prob = test_results.loc[sample_idx, \"prob_default\"]\n",
    "sample_true = test_results.loc[sample_idx, \"y_true\"]\n",
    "\n",
    "preprocessor = best_model.named_steps[\"preprocess\"]\n",
    "knn_estimator = best_model.named_steps[\"knn\"]\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "sample_transformed = preprocessor.transform(sample_x)\n",
    "\n",
    "nn = NearestNeighbors(\n",
    "    n_neighbors=min(5, knn_estimator.n_neighbors),\n",
    "    metric=knn_estimator.metric,\n",
    "    p=knn_estimator.p,\n",
    ")\n",
    "nn.fit(X_train_transformed)\n",
    "distances, indices = nn.kneighbors(sample_transformed)\n",
    "\n",
    "neighbor_records = (\n",
    "    X_train.iloc[indices[0]]\n",
    "    .assign(\n",
    "        distance=distances[0],\n",
    "        actual=y_train.iloc[indices[0]].values,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Sample applicant idx {sample_idx} | true={sample_true} | p(default)={sample_prob:.3f}\")\n",
    "display(sample_x.assign(prob_default=sample_prob, actual=sample_true))\n",
    "display(neighbor_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Risks, Fairness, and Compliance\n### 12.1. Subgroup checks\nCompare TPR/FPR/PPV across protected vs non-protected subgroups. Flag substantive differences.\n\n### 12.2. Ethical and regulatory implications\nAvoid direct sensitive attributes and obvious proxies. Document data governance and decision governance.\n\n### 12.3. Monitoring plan\nDrift alerts (data and performance); scheduled retraining; decision and human-override logs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_report(df, group_col):\n",
    "    rows = []\n",
    "    for value, subset in df.groupby(group_col):\n",
    "        counts = confusion_counts(subset[\"y_true\"], subset[\"y_pred\"])\n",
    "        tpr = counts[\"tp\"] / max(counts[\"tp\"] + counts[\"fn\"], 1)\n",
    "        fpr = counts[\"fp\"] / max(counts[\"fp\"] + counts[\"tn\"], 1)\n",
    "        ppv = counts[\"tp\"] / max(counts[\"tp\"] + counts[\"fp\"], 1)\n",
    "        util = cost_sensitive_utility(counts, normalize=True)\n",
    "        rows.append({\n",
    "            group_col: value,\n",
    "            \"customers\": len(subset),\n",
    "            \"default_rate\": subset[\"y_true\"].mean(),\n",
    "            \"tpr\": tpr,\n",
    "            \"fpr\": fpr,\n",
    "            \"ppv\": ppv,\n",
    "            \"utility_per_customer\": util,\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"utility_per_customer\", ascending=False)\n",
    "\n",
    "print(\"Fairness/segment checks\")\n",
    "sex_report = group_report(test_results, \"SEX\")\n",
    "education_report = group_report(test_results, \"EDUCATION\")\n",
    "display(sex_report)\n",
    "display(education_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Deployment Plan (MVP)\n### 13.1. Export\nSerialize the full pipeline, including preprocessing and scaling.\n\n### 13.2. Operational requirements\nAcceptable inference latency with indexes/precomputed neighborhoods if needed. Fallback policies if the service fails.\n\n### 13.3. Updates and retraining\nRetraining cadence and triggers for drift or utility degradation."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. Conclusions and Next Steps\n### 14.1. Key findings\nWith proper scaling and a utility-optimized threshold, KNN can improve utility vs simple rules and baselines.\n\n### 14.2. Improvement roadmap\n- Features: more recent behavioral variables, robust aggregations.  \n- Model: benchmark against more scalable methods (regularized logistic, trees, gradient boosting).  \n- Business: refine costs/benefits with actual LGD/recovery data."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Appendix A. Data Dictionary (operational summary)\n- LIMIT_BAL: assigned credit limit.  \n- SEX, EDUCATION, MARRIAGE, AGE: demographic characteristics.  \n- PAY_0 ... PAY_6: monthly payment status (ordinal, indicates delays).  \n- BILL_AMT1 ... BILL_AMT6: monthly billed amounts.  \n- PAY_AMT1 ... PAY_AMT6: monthly paid amounts.  \n- default_payment_next_month: binary target (1=default).  \nNote: use only information available at decision time; align feature time windows with the target horizon to prevent leakage."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Appendix B. Reproducibility Checklist\n- Fixed and recorded random seeds.  \n- Documented stratified splits.  \n- Pipeline with preprocessing inside CV.  \n- Library and dataset versions.  \n- Final hyperparameters and operating threshold $\\\\tau^*$ saved.  \n- Scripts/notebook with run instructions and artifact signatures."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Appendix C. Business Scenario Definitions (if no official inputs)\nTo run threshold optimization without official costs:  \n- Conservative scenario: FP very costly (high LGD), FN moderate (opportunity cost).  \n- Balanced scenario: FP and FN similar magnitude; maximize global utility.  \n- Growth-aggressive scenario: FN costly (missed growth), FP moderate; control losses via exposure caps.  \nReport results per scenario and select the one meeting risk constraints."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}